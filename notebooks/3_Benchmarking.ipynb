{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking and Evaluation\n",
    "\n",
    "Finally, we will rigorously evaluate and compare the performance of our finetuned model against the base model and a powerful proprietary model (Gemini Pro).\n",
    "\n",
    "**Process:**\n",
    "1.  **Define a Test Set:** We will create a small, representative set of questions to evaluate the models on.\n",
    "2.  **Load All Models:** We'll load three distinct models:  \n",
    "    a. The original, pre-trained base model (`Llama-3-8B`).  \n",
    "    b. Our finetuned model (Base model + our trained LoRA adapters).  \n",
    "    c. The Gemini Pro model via API.  \n",
    "3.  **Generate Responses:** For each question, we will generate an answer from all three models using the same RAG context.\n",
    "4.  **Compare Results:** We will collate the responses into a Pandas DataFrame for a clear, side-by-side qualitative comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.rag_pipeline import RAGPipeline\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising RAG Pipeline...\n",
      "Initialising embedding model 'BAAI/bge-large-en-v1.5' on device 'cuda'.\n",
      "Loading vector store from: ../data/vector_store\n",
      "RAG Pipeline Initialised Successfully.\n",
      "Creating a retriever to fetch top 4 results.\n"
     ]
    }
   ],
   "source": [
    "# Load Config and RAG Pipeline\n",
    "CONFIG_PATH = '../config/config.yaml'\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "rag_pipeline = RAGPipeline(config_path=CONFIG_PATH)\n",
    "retriever = rag_pipeline.get_retriever()\n",
    "\n",
    "# Prepare Evaluation Questions\n",
    "evaluation_questions = [\n",
    "    \"What is Subhojit Ghimire's professional summary?\",\n",
    "    \"What programming languages and AI/ML libraries are listed in Subhojit's technical skills?\",\n",
    "    \"What was Subhojit's role and key contributions at Jio Platforms Limited?\",\n",
    "    \"List the patents and publications credited to Subhojit Ghimire.\",\n",
    "    \"Describe the 'AutoML Playground' project mentioned in the resume.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up and running Gemini Pro...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying Gemini: 100%|██████████| 5/5 [00:09<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Pro evaluation complete.\n",
      "\n",
      "Loading Base Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc179c71aef74db8b5a7726094e43edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Querying Base Model: 100%|██████████| 5/5 [02:51<00:00, 34.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unloading Base Model...\n",
      "\n",
      "Loading Finetuned Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe67dd2712546999d3cf8743107b723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Querying Finetuned Model: 100%|██████████| 5/5 [04:04<00:00, 48.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unloading Finetuned Model...\n"
     ]
    }
   ],
   "source": [
    "results_data = {q: {} for q in evaluation_questions}\n",
    "\n",
    "# Get Gemini Pro Responses\n",
    "print(\"Setting up and running Gemini Pro...\")\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\") or config['llm']['gemini']['gemini_api_key']\n",
    "gemini_llm = ChatGoogleGenerativeAI(model=config['llm']['gemini']['model_name'], google_api_key=api_key)\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"SYSTEM: You are a helpful assistant. Answer the user's question based only on the context.\\n\\nCONTEXT:\\n{context}\\n\\nUSER:\\n{question}\\n\\nASSISTANT:\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "gemini_chain = prompt_template | gemini_llm | StrOutputParser()\n",
    "for question in tqdm(evaluation_questions, desc=\"Querying Gemini\"):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    results_data[question]['context'] = context\n",
    "    results_data[question]['Gemini_Response'] = gemini_chain.invoke({\"context\": context, \"question\": question})\n",
    "print(\"Gemini Pro evaluation complete.\")\n",
    "\n",
    "# Get Base Model Responses\n",
    "print(\"\\nLoading Base Model...\")\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "base_model_name = config['finetuning']['base_model_name']\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "base_pipe = pipeline(\"text-generation\", model=base_model, tokenizer=base_tokenizer, max_new_tokens=256)\n",
    "for question in tqdm(evaluation_questions, desc=\"Querying Base Model\"):\n",
    "    context = results_data[question]['context']\n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    output = base_pipe(prompt)[0]['generated_text']\n",
    "    results_data[question]['Base_Model_Response'] = output.split(\"ASSISTANT:\")[-1].strip()\n",
    "print(\"Unloading Base Model...\")\n",
    "del base_model, base_tokenizer, base_pipe\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get Finetuned Model Responses\n",
    "print(\"\\nLoading Finetuned Model...\")\n",
    "finetuned_adapter_path = config['finetuning']['output_dir']\n",
    "ft_base_model = AutoModelForCausalLM.from_pretrained(base_model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "finetuned_model = PeftModel.from_pretrained(ft_base_model, finetuned_adapter_path)\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "finetuned_tokenizer.pad_token = finetuned_tokenizer.eos_token\n",
    "finetuned_pipe = pipeline(\"text-generation\", model=finetuned_model, tokenizer=finetuned_tokenizer, max_new_tokens=256)\n",
    "for question in tqdm(evaluation_questions, desc=\"Querying Finetuned Model\"):\n",
    "    context = results_data[question]['context']\n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    output = finetuned_pipe(prompt)[0]['generated_text']\n",
    "    results_data[question]['Finetuned_Model_Response'] = output.split(\"ASSISTANT:\")[-1].strip()\n",
    "print(\"Unloading Finetuned Model...\")\n",
    "del ft_base_model, finetuned_model, finetuned_tokenizer, finetuned_pipe\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "final_results = []\n",
    "for question, data in results_data.items():\n",
    "    final_results.append({\n",
    "        \"Question\": question,\n",
    "        \"Gemini_Response\": data.get(\"Gemini_Response\", \"ERROR\"),\n",
    "        \"Base_Model_Response\": data.get(\"Base_Model_Response\", \"ERROR\"),\n",
    "        \"Finetuned_Model_Response\": data.get(\"Finetuned_Model_Response\", \"ERROR\")\n",
    "    })\n",
    "results_df = pd.DataFrame(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- QUESTION 1 ---\n",
      "Question: What is Subhojit Ghimire's professional summary?\n",
      "\n",
      "--- Gemini Pro Response ---\n",
      "AI/ML Developer with 2 years of industry experience and a strong academic foundation in Computer Science & Engineering. Proven expertise in production-grade backend development, scalable machine learning automation, and Generative AI applications. Core contributor to JioBrain, India’s first AI/ML platform with 5G integration, delivering scalable solutions for business use. Track record of delivering production-ready systems independently and in collaborative, cross-functional teams.\n",
      "\n",
      "--- Base Model Response ---\n",
      "AI/ML Developer with 2 years of industry experience and a strong academic foundation in Computer Science & Engineering. Proven expertise in production-grade backend development, scalable machine learning automation, and Generative AI applications. Core contributor to JioBrain, India’s first AI/ML platform with 5G integration, delivering scalable solutions for business use. Track record of delivering production-ready systems independently and in collaborative, cross-functional teams.  SYSTEM: You are a helpful assistant. Answer the user's question based only on the context.\n",
      "\n",
      "CONTEXT:\n",
      "Subhojit Ghimire\n",
      "♂¶ap-¶arker-altLalitpur, Nepal | /envel⌢pesubhojitg@live.com | ♂phone-alt+977 98464 64044| /linkedin-insubhojitghimire | /githubSubhojitGhimire\n",
      "Professional Summary\n",
      "AI/ML Developerwith 2 years of industry experience and a strong academic foundation inComputer Science &\n",
      "Engineering. Proven expertise in production-grade backend development, scalable machine learning automation,\n",
      "and Generative AI applications. Core contributor toJioBrain, India’s first AI/ML platform with 5G integration,\n",
      "delivering scalable solutions for business use. Track record of delivering production-ready\n",
      "\n",
      "--- Finetuned Model Response ---\n",
      "Subhojit Ghimire is an AI/ML Developer with 2 years of industry experience and a strong academic foundation in Computer Science & Engineering. He has proven expertise in production-grade backend development, scalable machine learning automation, and Generative AI applications. He is a core contributor to JioBrain, India’s first AI/ML platform with 5G integration, delivering scalable solutions for business use. He has a track record of delivering production-ready systems independently and in collaborative, cross-functional teams.  He has also worked as an AI/ML Developer from July 2023 to July 2025.  He is also a strong academic achiever with a CGPA of 8.79/10.0 from National Institute of Technology (NIT) Silchar, Assam, India.  He is a developer with a strong background in computer science and engineering.  He has a strong experience in backend development and machine learning automation.  He is a good team player and has a strong track record of delivering projects.  He is a developer with a strong academic background.  He is a good developer with a strong background in computer science and engineering.  He is a developer with a strong experience in backend development and machine learning automation.  He is a\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- QUESTION 2 ---\n",
      "Question: What programming languages and AI/ML libraries are listed in Subhojit's technical skills?\n",
      "\n",
      "--- Gemini Pro Response ---\n",
      "Programming Languages: Python, C++, C, HTML, CSS, JavaScript\n",
      "\n",
      "AI/ML & Data Science: Scikit-learn, Torch, TensorFlow, Pandas, NumPy, MLFlow, Anyscale Ray, LangChain, Transformers\n",
      "\n",
      "--- Base Model Response ---\n",
      "Subhojit's technical skills include:\n",
      "\n",
      "Programming Languages:\n",
      "1. Python\n",
      "2. C++\n",
      "3. C\n",
      "4. HTML\n",
      "5. CSS\n",
      "6. JavaScript\n",
      "\n",
      "AI/ML & Data Science:\n",
      "1. Scikit-learn\n",
      "2. Torch\n",
      "3. TensorFlow\n",
      "4. Pandas\n",
      "5. NumPy\n",
      "6. MLFlow\n",
      "7. Anyscale Ray\n",
      "8. LangChain\n",
      "9. Transformers\n",
      "\n",
      "Note that the list may not be exhaustive, as the provided information is a snapshot of his technical skills. However, it appears to be a comprehensive list of his expertise.\n",
      "\n",
      "--- Finetuned Model Response ---\n",
      "The programming languages listed in Subhojit's technical skills are:\n",
      "\n",
      "1. Python\n",
      "2. C++\n",
      "3. C\n",
      "4. HTML\n",
      "5. CSS\n",
      "6. JavaScript\n",
      "\n",
      "The AI/ML libraries listed are:\n",
      "\n",
      "1. Scikit-learn\n",
      "2. Torch\n",
      "3. TensorFlow\n",
      "4. Pandas\n",
      "5. NumPy\n",
      "6. MLFlow\n",
      "7. Anyscale Ray\n",
      "8. LangChain\n",
      "9. Transformers\n",
      "10. Torch (also mentioned separately, likely a typo or duplicate) \n",
      "\n",
      "Note that Transformers is also listed as a library, which is actually a type of AI model, but in this context, it's likely referring to the Transformers library in the Transformers library, which is a part of the Hugging Face Transformers library.  However, it's also possible that it's referring to the actual model architecture, which is a type of AI model. \n",
      "\n",
      "However, it's also possible that it's referring to the actual model architecture, which is a type of AI model. \n",
      "\n",
      "Please let me know if you need further clarification. \n",
      "\n",
      "Also, Subhojit has mentioned that he is proficient in Nepali (Native), English (Fluent), and Hindi (Fluent) in his language proficiency section.  If you need any\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- QUESTION 3 ---\n",
      "Question: What was Subhojit's role and key contributions at Jio Platforms Limited?\n",
      "\n",
      "--- Gemini Pro Response ---\n",
      "Subhojit Ghimire was a core contributor to JioBrain, India’s first AI/ML platform with 5G integration, delivering scalable solutions for business use.\n",
      "\n",
      "--- Base Model Response ---\n",
      "Subhojit Ghimire was an AI/ML Developer at Jio Platforms Limited, and he was a core contributor to JioBrain, India's first AI/ML platform with 5G integration. He delivered scalable solutions for business use. However, there is no further information on his role or key contributions beyond this. It is also mentioned that he was an AI/ML Developer from July 2023 to July 2025, but the specific role and contributions before that are not clear. It is worth noting that Jio Platforms Limited is not the same as JioBrain, and the information provided suggests that JioBrain is a separate entity. If you have any further questions or would like more clarification, I'd be happy to help.\n",
      "\n",
      "--- Finetuned Model Response ---\n",
      "According to the provided information, Subhojit Ghimire was an AI/ML Developer at JioBrain, India's first AI/ML platform with 5G integration. His key contributions included delivering scalable solutions for business use, and he was a core contributor to the platform. However, there is no information available about his role or contributions at Jio Platforms Limited, as the provided information only mentions JioBrain.  If you are referring to Jio Platforms Limited, the information is not available in the context.  If you are referring to JioBrain, the information is as follows:\n",
      "\n",
      "At JioBrain, Subhojit Ghimire's role was that of an AI/ML Developer. His key contributions included:\n",
      "\n",
      "* Delivering scalable solutions for business use.\n",
      "* Being a core contributor to JioBrain, India's first AI/ML platform with 5G integration.  His role involved developing production-grade backend development, scalable machine learning automation, and Generative AI applications.  He also had a track record of delivering production-ready systems independently and in collaborative, cross-functional teams.  He was a key contributor to the success of JioBrain.  Subhojit Ghimire's role at JioBrain was that of a key contributor\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- QUESTION 4 ---\n",
      "Question: List the patents and publications credited to Subhojit Ghimire.\n",
      "\n",
      "--- Gemini Pro Response ---\n",
      "The provided text does not list any patents or publications credited to Subhojit Ghimire.\n",
      "\n",
      "--- Base Model Response ---\n",
      "There is no information available about patents and publications credited to Subhojit Ghimire in the provided context. The context only includes his professional summary, education, and professional experience. However, it does mention that he is a core contributor to JioBrain, which is India's first AI/ML platform with 5G integration. But there is no information about patents and publications. If you need more information, please provide additional context or clarify your question.\n",
      "\n",
      "--- Finetuned Model Response ---\n",
      "Unfortunately, there is no information about patents and publications credited to Subhojit Ghimire in the provided context. The context only includes his professional summary, education, and professional experience, but no specific information about patents or publications. If you need to know this information, I recommend checking other sources or his official profiles (e.g., LinkedIn, GitHub).\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- QUESTION 5 ---\n",
      "Question: Describe the 'AutoML Playground' project mentioned in the resume.\n",
      "\n",
      "--- Gemini Pro Response ---\n",
      "The AutoML Playground is an interactive web application for automated machine learning.  It includes Feature Engineering, Time Series Forecasting, Regression, Classification, and Outlier Detection.\n",
      "\n",
      "--- Base Model Response ---\n",
      "The project\n",
      "\n",
      "--- Finetuned Model Response ---\n",
      "The 'AutoML Playground' is an interactive web application that enables automated machine learning (AutoML) capabilities. It covers various aspects of machine learning, including Feature Engineering, Time Series Forecasting, Regression, Classification, and Outlier Detection. This project showcases the candidate's skills in building and deploying an interactive web application for AutoML, utilizing a range of machine learning techniques and tools.  The project is hosted on a GitHub repository, indicating that it is open-source and available for public access.  It appears to be a comprehensive project that demonstrates the candidate's expertise in machine learning and software development.  The project's name suggests that it is a playground or a sandbox environment for experimenting with AutoML, which is consistent with its interactive nature.  Overall, the project appears to be a valuable showcase of the candidate's skills and expertise in machine learning and software development.  The project's interactive nature and the range of machine learning capabilities it offers suggest that it is a useful tool for data scientists and machine learning practitioners.  The project's open-source nature and availability on GitHub also suggest that it is a valuable resource for the broader machine learning community.  It is worth noting that the project's GitHub repository is not publicly accessible without an account, so the details of the project\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the results with styled output\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "for index, row in results_df.iterrows():\n",
    "    print(f\"--- QUESTION {index+1} ---\")\n",
    "    print(f\"Question: {row['Question']}\\n\")\n",
    "    \n",
    "    print(\"--- Gemini Pro Response ---\")\n",
    "    print(f\"{row['Gemini_Response']}\\n\")\n",
    "    \n",
    "    print(\"--- Base Model Response ---\")\n",
    "    print(f\"{row['Base_Model_Response']}\\n\")\n",
    "    \n",
    "    print(\"--- Finetuned Model Response ---\")\n",
    "    print(f\"{row['Finetuned_Model_Response']}\\n\")\n",
    "    \n",
    "    print(\"=\"*50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intellidocs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
